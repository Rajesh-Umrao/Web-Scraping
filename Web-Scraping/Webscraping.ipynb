{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.flipkart.com/search?q=new+launch+tv&sid=ckf%2Cczl&as=on&as-show=on&otracker=AS_QueryStore_OrganicAutoSuggest_1_12_na_na_ps&otracker1=AS_QueryStore_OrganicAutoSuggest_1_12_na_na_ps&as-pos=1&as-type=RECENT&suggestionId=new+launch+tv%7CTelevisions&requestId=33ae24d5-65fa-4e7d-ae1b-36f74371f62d&as-backfill=on&otracker=nmenu_sub_TVs%20%26%20Appliances_0_New%20Launches'\n",
    "r=requests.get(url).text\n",
    "# print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Flipcart Scaping \n",
    "#### A) Searching through TAGS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://www.flipkart.com/search?q=new+launch+tv&sid=ckf%2Cczl&as=on&as-show=on&otracker=AS_QueryStore_OrganicAutoSuggest_1_12_na_na_ps&otracker1=AS_QueryStore_OrganicAutoSuggest_1_12_na_na_ps&as-pos=1&as-type=RECENT&suggestionId=new+launch+tv%7CTelevisions&requestId=33ae24d5-65fa-4e7d-ae1b-36f74371f62d&as-backfill=on&otracker=nmenu_sub_TVs%20%26%20Appliances_0_New%20Launches'\n",
    "url=\"https://www.flipkart.com/search?q=new+launch+tv&sid=ckf%2Cczl&as=on&as-show=on&otracker=AS_QueryStore_OrganicAutoSuggest_1_12_na_na_ps&otracker1=AS_QueryStore_OrganicAutoSuggest_1_12_na_na_ps&as-pos=1&as-type=RECENT&suggestionId=new+launch+tv%7CTelevisions&requestId=33ae24d5-65fa-4e7d-ae1b-36f74371f62d&as-backfill=on&otracker=nmenu_sub_TVs%20%26%20Appliances_0_New%20Launches\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"\n",
    "}\n",
    "r = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(r.text, 'lxml')\n",
    "Product_name=soup.find_all('div', {'class':'KzDlHZ'})\n",
    "product_list=[]\n",
    "for product in Product_name:\n",
    "    na=product.string\n",
    "    # print(na)\n",
    "    product_list.append(na)  # or use price.text\n",
    "\n",
    "prices=soup.find_all('div', {'class':'Nx9bqj _4b5DiR'})\n",
    "price_list=[]\n",
    "for price in prices:\n",
    "    pr=price.string\n",
    "    price_list.append(pr)  # or use price.text\n",
    "\n",
    "df=pd.DataFrame({'Product Name': product_list, 'Price':price_list})\n",
    "# df.to_csv(\"C:\\\\Users\\\\Rajesh Umrao\\\\OneDrive\\\\Desktop\\\\Product.csv\", index=False, encoding='utf-8')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B) Searching Through Regression expression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern = re.compile(r'Price')\n",
    "# divs = soup.find_all('div', text=pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C) Searching in case of Nested HTML Tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<div class=\"product\">\n",
    "    <div class=\"name\">Product Name</div>\n",
    "    <div class=\"price\">â‚¹8,999</div>\n",
    "    <div class=\"details\">\n",
    "        <p>Detail 1</p>\n",
    "        <p>Detail 2</p>\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "# Access the parent product div\n",
    "product_div = soup.find('div', class_='product')\n",
    "\n",
    "# Navigate to child elements\n",
    "name_div = product_div.find('div', class_='name')\n",
    "price_div = product_div.find('div', class_='price')\n",
    "details_div = product_div.find('div', class_='details')\n",
    "\n",
    "print(\"Product Name:\", name_div.text)\n",
    "print(\"Price:\", price_div.text)\n",
    "\n",
    "# Navigate to nested details\n",
    "details = [p.text for p in details_div.find_all('p')]\n",
    "print(\"Details:\", details)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Data from Table of the website "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.iplt20.com/auction/2024\"\n",
    "r=requests.get(url)\n",
    "# print(r)\n",
    "\n",
    "soup=BeautifulSoup(r.text,\"lxml\")\n",
    "table=soup.find('table', class_='ih-td-tab auction-tbl')\n",
    "\n",
    "#Extract the headers of the table \n",
    "cols=[]\n",
    "for i in table.find_all('th'):\n",
    "    col=i.text\n",
    "    cols.append(col)\n",
    "# print(cols)\n",
    "\n",
    "# Extract rows\n",
    "rows = []\n",
    "for tr in table.find_all('tr'):\n",
    "    cells = tr.find_all('td')\n",
    "    if len(cells) > 0:\n",
    "        row = [cell.text.strip() for cell in cells]\n",
    "        rows.append(row)\n",
    "# print(rows)\n",
    "#convert headers list\n",
    "df=pd.DataFrame(rows, columns=cols)\n",
    "# df.to_csv(\"C:\\\\Users\\\\Rajesh Umrao\\\\OneDrive\\\\Desktop\\\\IPL.csv\", index=False, encoding='utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Data from multiple Pages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.flipkart.com/search?q=mobile&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&sort=popularity'\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"}\n",
    "r = requests.get(url, headers=headers)\n",
    "soup=BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "link = soup.find(\"div\", class_=\"DOjaWF gdgoEp\").find(\"a\", class_=\"_9QVEpD\").get(\"href\")\n",
    "base_url=\"https://www.flipkart.com\"+link\n",
    "\n",
    "#making general base link\n",
    "link=base_url.strip(\"2\")\n",
    "#create empty list for using in forloop condition\n",
    "product_list=[]\n",
    "price_list=[]\n",
    "\n",
    "for i in range(1,2):\n",
    "    pg_link= link + str(i)\n",
    "    rq = requests.get(pg_link, headers=headers)\n",
    "    final_soup=BeautifulSoup(rq.text, 'lxml')\n",
    "    Product_name=final_soup.find_all('div', {'class':'KzDlHZ'})\n",
    "    for product in Product_name:\n",
    "        name=product.string\n",
    "        product_list.append(name)  \n",
    "\n",
    "    prices=soup.find_all('div', {'class':'Nx9bqj _4b5DiR'})\n",
    "    for price in prices:\n",
    "        pr=price.string\n",
    "        price_list.append(pr) \n",
    "    \n",
    "print(len(product_list))\n",
    "print(len(price_list))\n",
    "df=pd.DataFrame({'Product Name': product_list, 'Price':price_list})\n",
    "# df.to_csv(\"C:\\\\Users\\\\Rajesh Umrao\\\\OneDrive\\\\Desktop\\\\Product.csv\", index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selenium "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the desired URL\n",
    "driver.get(\"https://www.uppclonline.com\")\n",
    "\n",
    "# Wait for the button to be clickable\n",
    "wait = WebDriverWait(driver,0)\n",
    "button = wait.until(EC.element_to_be_clickable((By.XPATH, \"/html/body/div[2]/div/div[3]/div[1]/div[4]/div/div[2]/div/div/div/form/div/a[1]/span\")))\n",
    "\n",
    "# Click the button\n",
    "button.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import time\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import requests\n",
    "\n",
    "# Set the path to the Tesseract executable (adjust this for your system)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Windows path example\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the desired URL\n",
    "driver.get(\"https://www.uppclonline.com\")\n",
    "\n",
    "# Wait for the button to be clickable and click it\n",
    "wait = WebDriverWait(driver,10)\n",
    "button = wait.until(EC.element_to_be_clickable((By.XPATH, \"/html/body/div[2]/div/div[3]/div[1]/div[4]/div/div[2]/div/div/div/form/div/a[1]/span\")))\n",
    "button.click()\n",
    "\n",
    "# Wait for the dropdown menu to be present\n",
    "dropdown = wait.until(EC.presence_of_element_located((By.XPATH, \"/html/body/div[2]/div/div[3]/div/div[3]/div[5]/div/div[2]/div/form/table/tbody/tr[3]/td[3]/div/select\")))\n",
    "\n",
    "# Create a Select object\n",
    "select = Select(dropdown)\n",
    "select.select_by_index(1)  # Index is 0-based, so index 1 selects the 2nd option\n",
    "\n",
    "# Input the account number\n",
    "account_number_field = wait.until(EC.presence_of_element_located((By.XPATH, \"/html/body/div[2]/div/div[3]/div/div[3]/div[5]/div/div[2]/div/form/table/tbody/tr[5]/td[3]/div/input\")))\n",
    "account_number_field.send_keys(\"6048778000\")\n",
    "\n",
    "# Input the password\n",
    "password_field = wait.until(EC.presence_of_element_located((By.XPATH, \"/html/body/div[2]/div/div[3]/div/div[3]/div[5]/div/div[2]/div/form/table/tbody/tr[7]/td[3]/div/input\")))\n",
    "password_field.send_keys(\"anuj5395*\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import time\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import requests\n",
    "\n",
    "# Set the path to the Tesseract executable (adjust this for your system)\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:/Users/Rajesh Umrao/Downloads/tesseract-ocr-setup-3.02.02.exe\"  # Windows path example\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open the desired URL\n",
    "driver.get(\"https://www.uppclonline.com\")\n",
    "\n",
    "# Wait for the button to be clickable and click it\n",
    "wait = WebDriverWait(driver,10)\n",
    "button = wait.until(EC.element_to_be_clickable((By.XPATH, \"/html/body/div[2]/div/div[3]/div[1]/div[4]/div/div[2]/div/div/div/form/div/a[1]/span\")))\n",
    "button.click()\n",
    "\n",
    "# Wait for the dropdown menu to be present\n",
    "dropdown = wait.until(EC.presence_of_element_located((By.XPATH, \"/html/body/div[2]/div/div[3]/div/div[3]/div[5]/div/div[2]/div/form/table/tbody/tr[3]/td[3]/div/select\")))\n",
    "\n",
    "# Create a Select object\n",
    "select = Select(dropdown)\n",
    "select.select_by_index(1)  # Index is 0-based, so index 1 selects the 2nd option\n",
    "\n",
    "# Input the account number\n",
    "account_number_field = wait.until(EC.presence_of_element_located((By.XPATH, \"/html/body/div[2]/div/div[3]/div/div[3]/div[5]/div/div[2]/div/form/table/tbody/tr[5]/td[3]/div/input\")))\n",
    "account_number_field.send_keys(\"7146840100\")\n",
    "\n",
    "# Input the password\n",
    "password_field = wait.until(EC.presence_of_element_located((By.XPATH, \"/html/body/div[2]/div/div[3]/div/div[3]/div[5]/div/div[2]/div/form/table/tbody/tr[7]/td[3]/div/input\")))\n",
    "password_field.send_keys(\"anuj5395*\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
